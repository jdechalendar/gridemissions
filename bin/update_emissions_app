#!/bin/bash

# Script to automate the gridemissions data updates on the VM
# Scheduled hourly on cron with the next line
# @hourly /home/ec2-user/bin/update_emissions_app


source /home/ec2-user/.bashrc
conda activate py38

# Run data update for webapp
update_gridemissionsdata
# ba_report --report 3

data_path=/data/ec2-user/analysis/
data_path_remote=/data/ec2-user/analysis/
server_name="SERVER_NAME_HERE"

# Update visualization on EC2
rsync -v ${data_path}webapp/last_update.txt emissions-bw-pub:${data_path_remote}webapp/last_update.txt
rsync -v ${data_path}webapp/EBA_raw.csv emissions-bw-pub:${data_path_remote}webapp/EBA_raw.csv
rsync -v ${data_path}webapp/EBA_elec.csv emissions-bw-pub:${data_path_remote}webapp/EBA_elec.csv
rsync -v ${data_path}webapp/EBA_co2.csv emissions-bw-pub:${data_path_remote}webapp/EBA_co2.csv
rsync -rv --delete ${data_path}webapp/d3map/ emissions-bw-pub:${data_path_remote}webapp/d3map

# Ping server so it reloads the data
curl ${server_name}/info

# Update data archive on S3
cp ${data_path}webapp/EBA_basic.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_co2.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_elec.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_objective.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_opt.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_raw.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_rolling.csv ${data_path}s3/.
cp ${data_path}webapp/EBA_weights.csv ${data_path}s3/.
cp ${data_path}webapp/last_update.txt ${data_path}s3/.
gzip -f ${data_path}s3/*.csv
aws s3 sync --sse AES256 --delete --exclude "*" --include "*.csv.gz" ${data_path}s3/ s3://gridemissions
aws s3 sync --sse AES256 --delete --exclude "*" --include "*.txt" ${data_path}s3/ s3://gridemissions
